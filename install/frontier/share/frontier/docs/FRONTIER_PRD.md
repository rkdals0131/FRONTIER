### **[Product Requirements Document]**

## FRONTIER (Frustum-based Refined Object Networking & Tracking via Intersection Engine for Ranging-data)

---

### **1. 한 줄 요약 (One-liner)**

**C++ 기반 '3D 공간 매칭 전문 엔진'**: 물리적으로 부정확한 2D 거리 기반 매칭을, 100% 룰베이스의 물리적으로 타당한 **3D 공간 교차(Intersection) 테스트**로 대체하여, 센서 퓨전의 정확성과 신뢰도를 극한으로 끌어올립니다.

### **2. 핵심 목표 (Core Objective)**

- **"현재 우리의 매칭 방식은 최선인가? 더 나은 대안은 없는가?" 라는 질문에 대한 구체적이고 강력한 답을 제시합니다.**
- `calico` 또는 HELIOS의 2D 평면 기반 매칭 방식이 가진 근본적인 한계(왜곡, 스케일 문제 등)를 해결하고, **'뷰 프러스텀(View Frustum)'**이라는 3D 공간 분석 기법의 우월성을 정량적으로 증명하여, 시스템의 핵심 로직을 대체할 강력한 근거를 마련합니다.

### **3. 기술 아키텍처 및 언어**

- **언어: C++ (프로토타이핑은 Python으로 선행)**
  - **선택 이유:** 3D 기하학(평면, 벡터, 행렬) 연산이 매우 빈번하게 발생하므로, C++과 `Eigen` 라이브러리를 사용하여 최고의 실시간 성능을 보장합니다.
  - **개발 전략:** 먼저 Python(`numpy`, `open3d`)으로 알고리즘의 개념과 성능을 빠르게 검증(PoC)한 후, 그 가치가 증명되면 C++로 포팅하여 제품 수준의 성능과 안정성을 확보하는 '하이브리드 개발 전략'을 사용합니다.
- **형태: ROS 2 노드**
  - 독립적인 '전문가 모듈' 노드로 동작하며, 매칭에 필요한 데이터를 입력받아 가장 정확한 '매칭 결과'를 발행합니다.

### **4. 입/출력 (Inputs & Outputs)**

- **구독 (Inputs):**
  1.  `라이다 3D 탐지 정보`: `/cone_detection/sorted_cones_time` (`vision_msgs/msg/Detection3DArray`)
  2.  `YOLO 2D 탐지 정보`: `/yolo/detections` (`vision_msgs/msg/Detection2DArray`)
  3.  `카메라 캘리브레이션 정보`: `/usb_cam/camera_info` (`sensor_msgs/msg/CameraInfo`)
  4.  `좌표계 정보`: `tf2`를 통해 라이다-카메라 간의 변환 행렬을 지속적으로 수신

- **발행 (Outputs):**
  1.  **`퓨전된 3D 객체 정보` (`/frontier/fused_detections`):**
      - **메시지 타입:** `vision_msgs/msg/Detection3DArray`
      - **내용:** 3D 공간상에서 라이다와 카메라의 연관 관계가 확립된 최종 객체 목록.
  2.  **`시각화 정보` (`/frontier/visualization`):**
      - **메시지 타입:** `visualization_msgs/msg/MarkerArray`
      - **내용:** 디버깅의 신! RViz에서 3D 공간에 그려지는 **뷰 프러스텀, 라이다 3D 박스, 그리고 매칭 결과를 보여주는 선** 등을 발행합니다.

### **5. Python PoC 구현 문서**

FRONTIER 프로젝트의 Python Proof-of-Concept 구현에 대한 상세 아키텍처와 개발 계획은 다음 문서를 참조하세요:

📘 **[FRONTIER Python PoC 구현 아키텍처](./FRONTIER_PYTHON_POC_ARCHITECTURE.md)**
- 패키지 구조 설계
- 핵심 모듈별 상세 구현 사항
- 테스트 계획 및 성능 벤치마크
- 개발 로드맵 및 성공 지표

### **6. 핵심 기능 및 단계별 구현 계획**

#### **1단계 (Python PoC): 뷰 프러스텀 생성기 (Frustum Generator)**
- **목표:** `CameraInfo`와 YOLO의 2D 바운딩 박스를 입력받아, 3D 공간상의 '바운딩 프러스텀'을 정의하는 Python 클래스/함수를 만듭니다.
- **구현:**
  - `image_geometry`의 `projectPixelTo3dRay()`를 활용하여 2D 박스의 네 꼭짓점을 3D 광선 벡터로 변환합니다.
  - 네 개의 광선과 카메라 원점을 이용해 프러스텀을 구성하는 6개 평면(Near, Far, Top, Bottom, Left, Right)의 방정식을 계산합니다.

#### **2단계 (Python PoC): 교차 엔진 (Intersection Engine)**
- **목표:** 라이다 클러스터의 3D 바운딩 박스와 1단계에서 생성된 프러스텀 간의 3D 공간 교차 여부 및 정도(IoU)를 계산합니다.
- **구현 (쉬운 방식부터):**
  - **Point-in-Frustum:** 라이다 클러스터의 포인트들이 프러스텀 6개 평면 '안쪽'에 포함되는지 검사하여, 포함된 포인트의 비율로 교차 정도를 근사합니다. `open3d`와 `numpy`로 빠르게 구현 가능합니다.
  - **(심화) AABB vs Frustum Overlap Test:** 정확한 3D IoU를 위해 컴퓨터 그래픽스의 'AABB-Frustum 교차 테스트' 알고리즘을 구현합니다.

#### **3단계 (Python PoC -> C++ Porting): 연관기 및 발행 노드 (Association & Publisher)**
- **목표:** 위 모듈들을 합쳐 실제 ROS 2 노드를 완성합니다.
- **구현:**
  1.  모든 (YOLO 프러스텀, 라이다 박스) 쌍에 대해 **'비용 행렬(Cost Matrix)'**을 생성합니다. `Cost(i, j) = 1.0 - IoU_3D(frustum_i, box_j)`
  2.  이 비용 행렬을 **헝가리안 알고리즘** (`scipy.optimize.linear_sum_assignment` 또는 C++ 구현체)에 입력하여, 전체 비용을 최소화하는 최적의 1:1 매칭을 찾습니다.
  3.  매칭된 쌍들을 하나의 '퓨전된 객체' 정보로 묶어 최종 토픽에 발행합니다.
  4.  디버깅을 위해 프러스텀과 박스, 매칭 선을 시각화 토픽에 발행합니다.

#### **4단계 (C++): 제품화 (Production-ready Implementation)**
- **목표:** Python 프로토타입에서 검증된 로직을 실시간 성능에 맞게 C++로 포팅합니다.
- **작업:**
  - `numpy` 연산은 `Eigen3` 라이브러리로 대체합니다.
  - 프러스텀 생성 및 교차 테스트 로직을 C++ 클래스로 깔끔하게 구현합니다.
  - 성능 최적화에 집중하여 프레임당 처리 시간이 목표치(예: 20ms) 이내로 들어오도록 만듭니다.


### **7. 기대 효과 및 가치 제안**

- **오탐의 근본적 해결:** "왜 저 멀리 있는 박스가 가까운 YOLO 탐지와 매칭되었는가?"와 같은 2D 투영의 고질적인 문제를 원천적으로 해결합니다.
- **신뢰성의 척도 제시:** 3D IoU 값 자체를 '퓨전의 신뢰도' 점수로 활용할 수 있습니다. IoU가 0.8 이상이면 매우 신뢰 높은 퓨전, 0.3 이하면 의심스러운 퓨전으로 판단하는 등, 시스템이 스스로의 결과를 평가하는 능력을 갖게 됩니다.
- **'외과수술적 개선'의 근거:** FRONTIER의 우월성이 증명되면, 기존 시스템(`calico`)의 매칭 부분만 FRONTIER의 로직으로 교체하는 '핀포인트' 개선이 가능해져, 최소한의 노력으로 최대의 성능 향상을 이끌어낼 수 있습니다.

---

## **8. 개선 제안사항 (Enhancement Suggestions)**

### **성능 최적화 및 확장성**

1. **다단계 매칭 파이프라인**
   - **1차 게이팅 (Coarse Filtering):**
     - Point-in-Frustum 테스트 (O(n))
     - 평면 거리 테스트 (거리 > 50m 제외)
     - 시야각 테스트 (FOV 외부 제외)
   - **2차 근사 IoU (Approximate IoU):**
     - 샘플링 기반 IoU (포인트의 10% 샘플)
     - 복셀화 기반 IoU (0.2m 그리드)
   - **3차 정밀 매칭 (Fine Matching):**
     - 헝가리안 알고리즘 적용
     - 타임아웃: 20ms

2. **비용행렬 복잡도 관리**
   - **최대 후보 제한:** 
     - YOLO 탐지: 최대 20개
     - 라이다 클러스터: 최대 30개
   - **거리 기반 게이팅:**
     - 근거리 (< 10m): 모든 후보 고려
     - 중거리 (10-30m): 시야각 ±30° 내 후보만
     - 원거리 (> 30m): 시야각 ±15° 내 후보만
   - **동적 임계값:**
     - IoU 임계값: 거리에 따라 0.3 ~ 0.7 조정

3. **멀티카메라 통합 전략**
   - **개별 매칭 후 통합:**
     - 각 카메라별 독립 매칭
     - 신뢰도 기반 가중 평균
   - **단일 비용행렬:**
     - 모든 카메라 프러스텀을 하나의 행렬에
     - 카메라별 가중치 적용
   - **우선순위 정책:**
     - 전방 카메라 > 측면 카메라
     - 고해상도 카메라 > 저해상도 카메라

4. **입력 메시지 정의**
   - `/cone_detection/sorted_cones_time` 명세:
     - 박스 정의: AABB (Axis-Aligned Bounding Box)
     - 프레임 기준: `base_link` 또는 `os_sensor`
     - 공분산 포함 여부: Optional
   - 시간 동기화:
     - 허용 오차: 50ms
     - 보간 정책: 선형 보간

### **알고리즘 개선**

5. **IoU 계산 최적화**
   - **SAT (Separating Axis Theorem):** OBB-Frustum 교차 테스트
   - **GJK (Gilbert-Johnson-Keerthi):** 볼록 다면체 교차
   - **GPU 가속:** CUDA 기반 병렬 처리

6. **헝가리안 알고리즘 구현**
   - **C++ 라이브러리 선택:**
     - `dlib`: 안정적, 쉬운 통합
     - `lap`: 최고 성능
     - 자체 구현: 최적화 가능
   - **N, M 상한:** 50 x 50 행렬
   - **타임아웃 정책:** 20ms 초과 시 greedy 매칭

### **KPI 및 수용 기준**
- **매칭 정확도:**
  - Precision: > 0.95
  - Recall: > 0.90
  - F1-Score: > 0.92
- **처리 성능:**
  - 평균 지연: < 15ms
  - 최대 지연: < 30ms
  - 처리율: > 20 Hz
- **IoU 품질:**
  - 평균 IoU (매칭된 쌍): > 0.6
  - 최소 IoU 임계값: 0.3

### **구현 우선순위**
1. Phase 1 (1주): Python PoC - 프러스텀 생성 및 Point-in-Frustum
2. Phase 2 (1주): Python PoC - IoU 계산 및 헝가리안 매칭
3. Phase 3 (2주): C++ 포팅 - 기본 기능
4. Phase 4 (1주): C++ 최적화 - 다단계 파이프라인
5. Phase 5 (1주): 멀티카메라 지원

### **테스트 및 검증**
- **단위 테스트:**
  - 프러스텀 생성 정확도
  - IoU 계산 정확도
  - 헝가리안 알고리즘 정확도
- **통합 테스트:**
  - 멀티카메라 시나리오
- **벤치마크:**
  - 기존 calico 대비 성능
  - 2D 매칭 vs 3D 매칭 정확도
- **스트레스 테스트:**
  - 최대 객체 수 (100개)
  - 최악 조건 (안개, 야간)